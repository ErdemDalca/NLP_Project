import os
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy import sparse
import joblib

# === Ayarlar ===
base_dir = os.path.dirname(__file__)
output_dir = os.path.join(base_dir, "..", "vector_outputs")

os.makedirs(output_dir, exist_ok=True)

input_files = {
    "lemma": os.path.join(base_dir, "..", "data", "lemmatized_sentences.csv"),
    "stem": os.path.join(base_dir, "..", "data", "stemmed_sentences.csv")
}
column_names = {
    "lemma": "Lemmatized",
    "stem": "Stemmed"
}

# === Her veri tipi iÃ§in tam TF-IDF oluÅŸtur
for dtype in ["lemma", "stem"]:
    print(f"\nðŸ”„ BaÅŸlÄ±yor: {dtype.upper()}")

    # Dosya yollarÄ±
    csv_path = input_files[dtype]
    column = column_names[dtype]
    output_npz = os.path.join(output_dir, f"tfidf_full_{dtype}.npz")
    output_vectorizer = os.path.join(output_dir, f"tfidf_vectorizer_{dtype}.pkl")

    # Veriyi oku
    df = pd.read_csv(csv_path)
    sentences = df[column].dropna().tolist()
    sentences = [" ".join(s.strip().split()) for s in sentences]

    # TF-IDF hesapla (tÃ¼m vocabulary)
    vectorizer = TfidfVectorizer()
    matrix = vectorizer.fit_transform(sentences)  # sparse matrix

    # Sparse matrisi kaydet
    sparse.save_npz(output_npz, matrix)

    # Vectorizer objesini sakla (kelimeler + IDF deÄŸerleri iÃ§in)
    joblib.dump(vectorizer, output_vectorizer)

    print(f"âœ… TF-IDF matrisi kaydedildi: {output_npz}")
    print(f"âœ… TF-IDF vectorizer kaydedildi: {output_vectorizer}")
    print(f"ðŸ”¢ VektÃ¶r boyutu: {matrix.shape} (satÄ±r=cÃ¼mle, sÃ¼tun=kelime)")
